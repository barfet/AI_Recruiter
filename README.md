# AI-Powered Recruitment Platform

An intelligent recruitment platform that leverages LLMs and vector search for advanced candidate-job matching and skill analysis.

## ğŸ¯ Core Features

- **Intelligent Matching**: Advanced semantic matching between job requirements and candidate profiles
- **Skill Analysis**: Deep skill gap analysis and recommendations
- **Interview Support**: Dynamic interview question generation and evaluation
- **Vector Search**: Efficient similarity search for candidates and jobs
- **Compliance Management**: Automated compliance checking and reporting

## ğŸ— Architecture

```
src/
â”œâ”€â”€ agent/                 # AI agent components
â”‚   â”œâ”€â”€ chains.py         # LangChain processing chains
â”‚   â”œâ”€â”€ tools.py          # Specialized AI tools
â”‚   â””â”€â”€ prompts.py        # Prompt templates
â”œâ”€â”€ api/                   # API endpoints
â”‚   â””â”€â”€ routes/           # Route definitions
â”œâ”€â”€ core/                 # Core functionality
â”‚   â”œâ”€â”€ config.py         # Configuration management
â”‚   â””â”€â”€ logging.py        # Logging setup
â”œâ”€â”€ data/                 # Data management
â”‚   â”œâ”€â”€ managers/         # Data access layer
â”‚   â””â”€â”€ cleaning/         # Data cleaning utilities
â”œâ”€â”€ services/            # Business logic
â”‚   â””â”€â”€ job_discovery.py  # Job matching service
â””â”€â”€ vector_store/        # Vector database interface
    â””â”€â”€ chroma_store.py   # ChromaDB implementation
```

## ğŸ›  Tech Stack

- **Python 3.9+**: Core language
- **LangChain**: LLM orchestration
- **OpenAI GPT-4**: Language model
- **ChromaDB**: Vector storage
- **FastAPI**: API framework
- **Pydantic**: Data validation
- **pytest**: Testing framework

## ğŸš€ Getting Started

1. **Environment Setup**
```bash
python -m venv venv
source venv/bin/activate  # Unix
.\venv\Scripts\activate   # Windows
pip install -r requirements.txt
```

2. **Configuration**
```bash
cp .env.example .env
# Edit .env with your settings
```

3. **Run Tests**
```bash
pytest
```

4. **Start Server**
```bash
uvicorn src.api.main:app --reload
```

## ğŸ“‹ Development Guidelines

### Code Structure

- **Agents**: Inherit from `BaseAgent`, implement `_run` method
- **Chains**: Follow `CandidateJobMatchChain` pattern
- **Tools**: Inherit from `BaseTool`, implement required methods
- **Managers**: Follow `BaseManager` pattern with logging

### AI Components

- **Prompts**: 
  - Include examples and context
  - Validate outputs
  - Handle edge cases
- **LLM Calls**:
  - Set appropriate temperature
  - Implement timeout handling
  - Include error recovery
- **Embeddings**:
  - Specify model and dimensions
  - Implement batch processing
  - Handle OOV tokens

### Testing

- Unit tests for all components
- Integration tests for chains
- Mock external services
- Test async functionality
- Validate outputs

## ğŸ” Key Patterns

### Chain Pattern
```python
class CustomChain:
    def __init__(self, llm: Optional[ChatOpenAI] = None):
        self.llm = llm or ChatOpenAI(temperature=0.0)
        self._init_chains()

    def _init_chains(self):
        # Initialize component chains
        pass

    async def run(self, **kwargs):
        # Chain execution logic
        pass
```

### Manager Pattern
```python
class CustomManager(BaseManager):
    def __init__(self):
        super().__init__()
        self.logger = setup_logger(__name__)

    async def process_data(self):
        try:
            # Processing logic
            pass
        except Exception as e:
            self.logger.error(f"Error: {str(e)}")
            raise
```

## ğŸ¤ Contributing

1. Follow the `.cursorrules` configuration
2. Ensure comprehensive documentation
3. Add tests for new features
4. Update relevant documentation

## ğŸ“š Documentation Standards

- Google-style docstrings
- Include Args, Returns, Raises sections
- Provide usage examples
- Document class attributes and methods

## ğŸ” Security

- Implement rate limiting
- Validate all inputs
- Sanitize LLM outputs
- Handle sensitive data appropriately

## ğŸ“ˆ Performance

- Use async/await for I/O operations
- Implement caching where appropriate
- Batch process embeddings
- Monitor LLM token usage

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ”— Links

- [Technical Architecture](docs/architecture.md)
- [API Documentation](docs/api.md)
- [Development Guide](docs/development.md)
